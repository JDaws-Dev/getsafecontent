# I Watched My Daughter Disappear Into YouTube and Built an App to Get Her Back

*The moment I realized YouTube Kids wasn't protecting anyone*

---

Last summer, I walked into the living room to find my 8-year-old daughter Emma watching a video titled "5 CREEPIEST Things Found in Kids' Bedrooms." She'd been watching YouTube Kids.

YouTube *Kids*.

I grabbed the iPad and scrolled through her history. What I found made my stomach drop:

- Minecraft videos that devolved into characters screaming obscenities
- "Satisfying" compilation videos with disturbing AI-generated imagery
- A "kids' cartoon" featuring characters in weirdly adult situations
- An ASMR video of someone whispering about their "dark thoughts"

All of this had passed through YouTube Kids' algorithms without a single flag.

I sat down next to her. "Honey, how did you find these videos?"

She shrugged. "They just showed up."

That's when I understood the real problem.

---

## The Lie We've Been Told

As parents, we've been given an impossible choice:

**Option A:** Give our kids access to the platforms they want—YouTube, Spotify, Apple Music—and accept that algorithms will eventually push them toward content we'd never approve.

**Option B:** Lock them into "kids" versions of these platforms, which are either mind-numbingly boring (so they'll circumvent them) or still somehow filled with weird content that slips through.

For years, I tried Option B. YouTube Kids. Spotify Kids. Curated playlists. Approved apps only.

My kids hated it. And honestly? I didn't blame them.

My son wanted to watch Dude Perfect, not Cocomelon. My daughter wanted Taylor Swift's actual albums, not "Baby's First Classical." They felt insulted by "kids" platforms that treated 10-year-olds the same as toddlers.

So I'd relent. I'd give them regular YouTube "just for this one channel." I'd let them have real Spotify "but only with parental controls on."

The cycle repeated: relax restrictions, discover something horrifying, panic, lock everything down, wait for complaints, relax restrictions again.

Sound familiar?

---

## The Algorithm Doesn't Care About Your Kids

Here's what I finally understood:

YouTube's algorithm is optimized for *engagement*, not child safety. Spotify's Discovery Weekly doesn't know your kid is 9. Apple Music's "suggested songs" will absolutely recommend the explicit version if it thinks that's what keeps them listening.

And the "kids" versions? They're just regular platforms with a crude filter slapped on top. They still use the same engagement-maximizing algorithms. They still auto-play toward whatever keeps eyeballs glued to screens.

The content moderation teams at these companies aren't bad people. But they're fighting a losing battle. Millions of hours of content get uploaded every day. AI moderation catches the obvious stuff—nudity, violence—but completely misses context.

A video of Minecraft Steve getting "murdered" by zombies while a creator screams "OH MY GOD HE'S DEAD!"? That passes moderation.

A song where the F-word is bleeped but the entire message is about self-harm? That's "clean" as far as Spotify is concerned.

The system isn't broken. It was never designed to protect kids in the first place.

---

## What I Actually Wanted

After the YouTube Kids incident, I sat down and wrote out exactly what I wanted:

1. **Real platforms, not kiddie substitutes.** I want my daughter to be able to search for Taylor Swift on Apple Music and actually find Taylor Swift—not a lullaby cover version.

2. **My approval, not an algorithm's.** If she wants to add a song to her library, I want to see it first. If my son wants to subscribe to a YouTube channel, I should approve it.

3. **Visibility into what they're consuming.** Not spy software—I don't want to read their messages or track their location. Just: what songs are they listening to? What channels are they watching? What books are they reading?

4. **Age-appropriate progression.** My 14-year-old should have more freedom than my 8-year-old. That should be easy to manage.

5. **Something my kids would actually use.** If they hate it, they'll find workarounds. It needs to feel like a real app, not digital prison.

I looked for an app that did this.

It didn't exist.

---

## So I Built It

I'm a software developer. Not a parenting expert, not a child psychologist—just a dad who knows how to code and was tired of the status quo.

I started with music because that's where my daughter spent most of her time. I built an app that lets her search Apple Music's entire catalog, but every song she wants goes into a queue for me to approve. She gets access to the real Taylor Swift. I just see each song before it lands in her library.

The first version was ugly. Really ugly. But it worked.

My daughter loved it. She didn't feel like she was using a "baby app." She was using a real music app—she just knew Dad had to approve things first. She accepted that trade-off because she finally had access to the music she actually wanted.

I built the same thing for YouTube. Same principle: real YouTube, real creators, but every channel subscription comes to me first. My son can request to follow Dude Perfect, I approve it, and he's good to go. Meanwhile, the algorithm can suggest whatever garbage it wants—he can't act on it without my okay.

Then books. Same concept.

---

## What Surprised Me

Two things happened that I didn't expect:

**First, my kids started asking for less.**

When requesting content requires a tap instead of mindless scrolling, they became more intentional. My daughter doesn't request every song she hears—just the ones she actually wants. My son doesn't binge-request channels—he picks the ones he cares about.

The friction isn't a bug. It's a feature.

**Second, I started saying yes more.**

When I could see exactly what they were asking for—not just "can I have YouTube"—I realized most of their requests were totally reasonable. I wasn't blocking everything. I was just blocking the 5% that I actually had concerns about.

The conflict dropped dramatically. No more vague arguments about "YouTube time." Just specific, easy conversations: "Hey, this creator's content is a little intense for your age. Let's wait a year."

---

## Safe Family

I originally built these apps just for my family. But other parents started asking about them.

"Can my kids use that music app?"

"How did you make that YouTube thing?"

So I turned them into real products. I call the suite **Safe Family**:

- **SafeTunes** — Apple Music with parental approval
- **SafeTube** — YouTube with parental approval
- **SafeReads** — Any book with parental approval

They're not surveillance apps. I'm not reading my kids' messages or tracking their GPS. I'm just sitting between them and platforms that weren't designed with their wellbeing in mind.

And the philosophy is simple: **Your kids should have access to real platforms. You should have visibility and approval over what they access.**

That's it. That's the whole thing.

---

## For the Parents Still in the Cycle

If you're stuck in the same loop I was—restrict, relent, regret, repeat—I get it.

You're not a bad parent for giving your kid YouTube. You're not overprotective for wanting guardrails. You've just been given bad options by companies that make money when your kids can't look away.

The solution isn't to ban screens or to give up and let algorithms parent our children.

The solution is *better tools*.

That's what I built. I hope it helps your family like it helped mine.

---

*Jeremiah Daws is the founder of Safe Family. He lives with his wife and four kids, all of whom have strong opinions about which songs deserve approval.*

**[Try Safe Family free for 7 days](https://getsafefamily.com)**

---

*If this resonated with you, share it with a parent who's fighting the same battle. We're all figuring this out together.*
